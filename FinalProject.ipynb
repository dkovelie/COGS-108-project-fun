{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important\n",
    "\n",
    "- ONE, and only one, member of your group should upload this notebook to TritonED. \n",
    "- Each member of the group will receive the same grade on this assignment. \n",
    "- Keep the file name the same: submit the file 'FinalProject.ipynb'.\n",
    "- Only upload the .ipynb file to TED, do not upload any associted data. Make sure that for cells in which you want graders to see output that these cells have been executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Members: Fill in the Student IDs of each group member here\n",
    "\n",
    "Replace the lines below to list each persons full student ID, ucsd email and full name.\n",
    "\n",
    "- A12814729\n",
    "- A11983710\n",
    "- A91097653\n",
    "- A13497348\n",
    "- A12433857\n",
    "- A11774341\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start your project here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The imports for this project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sp\n",
    "import matplotlib as mplot\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chisquare, normaltest\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeksalesdb = pd.read_csv('train.csv')\n",
    "stores = pd.read_csv('stores.csv' , dtype = {'Store': int})\n",
    "features = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.drop(columns = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts weeksalesdb rows into dict and merging departments\n",
    "agg_sales = defaultdict(int)\n",
    "for ind, sale in weeksalesdb.iterrows():\n",
    "    agg_sales[str(sale['Store'])+'.'+sale['Date']] += sale['Weekly_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts back into db with updated sales value\n",
    "storesales = pd.DataFrame(columns=['Store','Date','Weekly_Sales'])\n",
    "\n",
    "for key, value in agg_sales.items():\n",
    "    store, date = key.split('.')\n",
    "    newrow = [store, date, value]\n",
    "    storesales.loc[len(storesales)] = newrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert date to integer\n",
    "def convert_date(date):\n",
    "    date = date.strip()\n",
    "    date = date.replace('-','')\n",
    "    date = date.strip()\n",
    "    return int(date)\n",
    "\n",
    "#convert date columns\n",
    "storesales['Date'] = storesales['Date'].apply(convert_date)\n",
    "features['Date'] = features['Date'].apply(convert_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert store column to int (was str)\n",
    "storesales['Store'] = pd.to_numeric(storesales['Store'])\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exported csv files\n",
    "storesales.to_csv('storesales.csv')\n",
    "features.to_csv('features2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged two dataframes together on the store and date column\n",
    "merged = pd.merge(storesales, features, on =['Store', 'Date'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed rows where unemployment data was empty\n",
    "merged.dropna(subset = ['Unemployment'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export cleaned features\n",
    "merged.to_csv('features_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checked for outliers in the weekly sales column, most of these are on or near holidays.\n",
    "outliers = merged[merged['Weekly_Sales'] > merged['Weekly_Sales'].mean() + 3 * merged['Weekly_Sales'].std()]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.plot.scatter(x='Temperature', y='Unemployment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['Temperature'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('features_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sales, pred_sales = patsy.dmatrices('Unemployment ~ Weekly_Sales', features)\n",
    "mod_sales = sm.OLS(out_sales, pred_sales)\n",
    "res_sales = mod_sales.fit()\n",
    "\n",
    "out_temp, pred_temp = patsy.dmatrices('Unemployment ~ Temperature', features)\n",
    "mod_temp = sm.OLS(out_temp, pred_temp)\n",
    "res_temp = mod_temp.fit()\n",
    "\n",
    "out_fuel, pred_fuel = patsy.dmatrices('Unemployment ~ Fuel_Price', features)\n",
    "mod_fuel = sm.OLS(out_fuel, pred_fuel)\n",
    "res_fuel = mod_fuel.fit()\n",
    "\n",
    "out_cpi, pred_cpi = patsy.dmatrices('Unemployment ~ CPI', features)\n",
    "mod_cpi = sm.OLS(out_cpi, pred_cpi)\n",
    "res_cpi = mod_cpi.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_sales.summary(), res_temp.summary(), res_fuel.summary(), res_cpi.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1, pred1 = patsy.dmatrices('Unemployment ~ Weekly_Sales + CPI', features)\n",
    "mod1 = sm.OLS(out1, pred1)\n",
    "res1 = mod1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2, pred2 = patsy.dmatrices('Unemployment ~ Weekly_Sales + CPI + Fuel_Price + Temperature', features)\n",
    "mod2 = sm.OLS(out2, pred2)\n",
    "res2 = mod2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizevalue(self, df, label):\n",
    "    df = df.copy(deep=True)\n",
    "    series = df.loc[:, label]\n",
    "    avg = series.mean()\n",
    "    stdv = series.std()\n",
    "    series_standardized = (series - avg)/stdv\n",
    "    return series_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns we want to standardize\n",
    "numericcolumns = features[['Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']]\n",
    "#get the column names\n",
    "names = numericcolumns.columns\n",
    "#create scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#apply transformation\n",
    "normaled = scaler.fit_transform(numericcolumns)\n",
    "normaled = pd.DataFrame(normaled, columns=names)\n",
    "#delete the columns to be replaced with new values\n",
    "features_normal = features.drop(labels = names, axis = 'columns')\n",
    "#add in the columns from the normalized df\n",
    "features_normal[names] = normaled\n",
    "#rearrange columns to be like original features\n",
    "features_normal = features_normal[features.columns]\n",
    "#export csv file\n",
    "features_normal.to_csv('features_normal.csv', index = False)\n",
    "\n",
    "features_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Privacy/Ethics Concerns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
